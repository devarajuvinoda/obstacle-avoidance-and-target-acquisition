# obstacle-avoidance-and-target-acquisition

In this project we used deep deterministic policy gradient(DDPG) algorithm for obstacle avoidance and target acquisition task. We learnt about simulation software Webots and RL interface library Deepbots. We understood the mathematical concepts behind differential drive and DDPG algo- rithm. We created Webots world file which includes the environment of the robot. We implemented the controller of robot and supervisor and finally interfaced the supervisor with DDPG algorithm using Deepbots library. We also ran the experiment with multiple setup which includes fixed initial robot and target position and random robot and target position and their combinations, along with or without obstacles. We found out that DDPG algorithm works well when there are no obstacles, even if initial robot and target position is randomized. With obstacles, performance of DDPG algorithm was great when the position of robot, target and obstacles were fixed. However, DDPG algorithm did not give positive result when the position of the obstacles were randomized.

![arena_path1](https://user-images.githubusercontent.com/31110469/117312891-0a430a00-aea3-11eb-92a2-b86a26272f6f.png)
